{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [강의] BeautifulSoup 사용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML을 불러와 CSS 셀렉터로 선택하여 리스트로 반환해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<ul> \n",
    "    <li>1교시</li>\n",
    "    <li>2교시</li>\n",
    "</ul>\n",
    "<ol> \n",
    "    <li>3교시</li>\n",
    "    <li>4교시</li>\n",
    "</ol>\n",
    "\"\"\"\n",
    "soup = BeautifulSoup( html,\"html5lib\" )\n",
    "list_data = soup.select( \"ol li\" )\n",
    "\n",
    "print(list_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선택한 Tag객체의 리스트를 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in list_data:\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 선택한 Tag객체의 리스트에서 텍스트만 출력해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for data in list_data:\n",
    "    print(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue;\">[연습]</font> 특정 데이터만 선택해 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 태그는 스크래핑을 통해 데이터를 가져오기 위한 자료이다. 이 자료로부터 html에 저장된 태그에서 매출액/100/200을 화면에 출력하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup # BeautifulSoup 라이브러리 호출\n",
    "# HTML과 table 태그를 활용하여 구성\n",
    "html = \"\"\"\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th> 재무정보 </th>\n",
    "            <th> 2018 </th>\n",
    "            <th> 2019 </th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td> 매출액 </td>\n",
    "            <td> 100 </td>\n",
    "            <td> 200 </td>\n",
    "        </tr>  \n",
    "    </body>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup( html,\"html5lib\" )\n",
    "list_data = soup.select( \"table > tbody > tr > td\")\n",
    "\n",
    "for data in list_data:\n",
    "    print(data.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 태그는 스크래핑을 통해 데이터를 가져오기 위한 자료이다. 100을 선택해 화면에 출력하시오. (nth-child 또는 nth-of-type 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# HTML과 table 태그를 활용하여 구성\n",
    "html = \"\"\"\n",
    "<table>\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th> 재무정보 </th>\n",
    "            <th> 2018 </th>\n",
    "            <th> 2019 </th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td> 매출액 </td>\n",
    "            <td> 100 </td>\n",
    "            <td> 200 </td>\n",
    "        </tr>  \n",
    "    </body>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup( html,\"html5lib\" )\n",
    "list_data = soup.select( \"table > tbody > tr > td:nth-of-type(2)\")\n",
    "\n",
    "print(list_data[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 태그는 스크래핑을 통해 데이터를 가져오기 위한 자료이다. 새우깡을 선택해 화면에 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML과 table 태그를 활용하여 구성\n",
    "html = \"\"\"\n",
    "<div>\n",
    "  <div class=\"snack\">\n",
    "    <div id=\"first\"> 양파링 </div>\n",
    "    <div id=\"second\"> 새우깡 </div>\n",
    "  </div>\n",
    "  <div class=\"icecream\">\n",
    "    <div> 빵빠레 </div>\n",
    "    <div> 죠스바 </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup( html,\"html5lib\" )\n",
    "data = soup.select( \"#second\")\n",
    "\n",
    "print(data[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 아래 태그는 스크래핑을 통해 데이터를 가져오기 위한 자료이다. 죠스바을 선택해 화면에 출력하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# HTML과 table 태그를 활용하여 구성\n",
    "html = \"\"\"\n",
    "<div>\n",
    "  <div class=\"snack\">\n",
    "    <div id=\"first\"> 양파링 </div>\n",
    "    <div id=\"second\"> 새우깡 </div>\n",
    "  </div>\n",
    "  <div class=\"icecream\">\n",
    "    <div> 빵빠레 </div>\n",
    "    <div> 죠스바 </div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup( html,\"html5lib\" )\n",
    "data = soup.select( \".icecream > div:nth-of-type(2)\")\n",
    "\n",
    "print(data[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue;\">[실습1]</font> 네이버 헤드라인 뉴스를 출력하라.\n",
    "페이지 : https://news.naver.com/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\"User-Agent\":\"\"} # 크롤링 방지하는 사이트에서 User-Agent 확인을 위해 headers 설정\n",
    "url = \"https://news.naver.com/\"\n",
    "html = requests.get(url, headers = headers, verify=False)\n",
    "html = html.text\n",
    "\n",
    "soup = BeautifulSoup(html, \"html5lib\")\n",
    "elements = soup.select(\"div.hdline_article_tit > a\")\n",
    "\n",
    "for i in elements :\n",
    "    print(i.text.strip()) # strip 공백제거 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue;\">[실습2]</font> 다음 링크의 네이버 영화 리뷰 댓글 4개를 스크래핑 하라.\n",
    "페이지 : https://movie.naver.com/movie/bi/mi/review.nhn?code=159866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\"User-Agent\":\"\"} # 크롤링 방지하는 사이트에서 User-Agent 확인을 위해 headers 설정\n",
    "url = \"https://movie.naver.com/movie/bi/mi/review.nhn?code=159866\"\n",
    "html = requests.get(url, headers = headers, verify=False)\n",
    "\n",
    "soup = BeautifulSoup(html.content,\"html5lib\")\n",
    "\n",
    "elements = soup.select(\"ul.rvw_list_area > li > a > strong\")\n",
    "#elements = soup.find(\"ul\",{\"class\":\"rvw_list_area\"}).find_all(\"strong\") #select 대신 find로 검색 가능\n",
    "\n",
    "for i in elements[0:4] : #4개만 가져오기 \n",
    "    print(i.text.strip()) # strip 공백제거 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue;\">[실습3]</font> 네이버 종목 토론실의 댓글 5개의 제목 (문자열)을 리스트에 저장하라.\n",
    "페이지 : https://finance.naver.com/item/board.nhn?code=005490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 임시 user-agent 작성해서 사용\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36\"}\n",
    "url = \"https://finance.naver.com/item/board.nhn?code=005490\"\n",
    "html = requests.get(url, headers = headers, verify=False).text\n",
    "\n",
    "soup = BeautifulSoup(html,\"html5lib\")\n",
    "\n",
    "elements = soup.find_all(\"td\", {\"class\":\"title\"}) #find_all과 find 다른점 설명 할 것\n",
    "\n",
    "posco = [] # 리스트 생성\n",
    "\n",
    "for i in elements[0:5] :\n",
    "    posco.append(i.find(\"a\")[\"title\"])\n",
    "\n",
    "print(posco) # 리스트 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue;\">[실습4]</font> 포스코 PER, PBR을 스크래핑하고 출력하라.\n",
    "페이지 : https://finance.naver.com/item/main.nhn?code=005490 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 임시 user-agent 작성해서 사용\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)AppleWebKit/537.36 (KHTML, like Gecko) Chrome/73.0.3683.86 Safari/537.36\"}\n",
    "url = \"https://finance.naver.com/item/board.nhn?code=005490\"\n",
    "html = requests.get(url, headers = headers, verify=False).text\n",
    "\n",
    "soup = BeautifulSoup(html,\"html5lib\") \n",
    "\n",
    "elements_per = soup.select(\"em#_per\")\n",
    "elements_pbr = soup.select(\"em#_pbr\")\n",
    "\n",
    "print(\"PER : \" + elements_per[0].text)\n",
    "print(\"PBR : \" + elements_pbr[0].text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
